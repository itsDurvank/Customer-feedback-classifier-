ğŸ¤– Customer Feedback Analyzer: Project Summary
The Customer Feedback Analyzer is an advanced Natural Language Processing (NLP) application that automatically classifies customer feedback into actionable categories using fine-tuned BERT-based transformer models from Hugging Face. The project demonstrates an end-to-end Machine Learning Engineering pipeline from training to real-time deployment.

ğŸ¯ Project Overview & Classification
The system is an AI assistant that analyzes feedback text and classifies it into one of 8 distinct categories: Bug Report (ğŸ), Feature Request (ğŸ’¡), Praise (ğŸ‰), Complaint (ğŸ˜ ), Question (â“), Usage Tip (ğŸ’¡), Documentation (ğŸ“„), and Other (ğŸ”–).

It leverages transfer learning, adapting a pre-trained BERT model for the specific task of sequence classification on customer feedback data.

Metric	Score
Accuracy	99.1%
F1-Score	0.990
Inference Speed	< 100ms per classification

Export to Sheets
ğŸ—ï¸ Project Architecture
The system follows a clean, modular architecture:

System Components
Input Layer: Streamlit web interface (app.py) for user interaction.

Processing Layer: Fine-tuned BERT model loaded via the Hugging Face transformers library (inference.py).

Analysis Layer: Confidence scoring and result interpretation.

Output Layer: Categorized results displayed with confidence scores and logs.

Training Pipeline
The training process, handled by finetune_classifier.py, involves:

Data Loading: Read labeled feedback examples (JSONL format).

Data Splitting: Separate training and validation sets (split_train_test.py).

Fine-tuning: Adapt the pre-trained BERT model using PyTorch and Hugging Face Trainer.

Evaluation: Measure performance metrics.

Model Saving: Store the trained model to disk in the models/feedback_classifier directory.

ğŸ“ File Structure and Implementation
The project is organized with dedicated files for each major function:

customer-feedback-analyzer/
â”œâ”€â”€ app.py                      # ğŸ¨ Main Streamlit web application interface.
â”œâ”€â”€ inference.py                # ğŸ§  AI model inference engine (loads model and makes predictions).
â”œâ”€â”€ finetune_classifier.py      # ğŸ“ Model training script (fine-tunes BERT).
â”œâ”€â”€ compare_models.py           # ğŸ“Š Model performance comparison utility.
â”œâ”€â”€ split_train_test.py         # âœ‚ï¸ Data splitting utility (creates train/test sets).
â”œâ”€â”€ requirements.txt            # ğŸ“¦ Python dependencies (Transformers, Streamlit, PyTorch, etc.).
â”œâ”€â”€ data/                       # ğŸ“Š Training and test data files.
â”œâ”€â”€ models/                     # ğŸ¤– Trained AI models (e.g., feedback_classifier/).
â””â”€â”€ assets/                     # ğŸ–¼ï¸ Images and documentation assets.
Key Technical Implementations
Model Loading (in inference.py): Uses AutoTokenizer and AutoModelForSequenceClassification from the transformers library to load the trained model, and utilizes a pipeline with GPU support for efficient real-time classification.

Training Configuration (in finetune_classifier.py): Sets up the TrainingArguments, including num_train_epochs=3, logging, and load_best_model_at_end=True to ensure the best performing model is saved.

Web App (in app.py): Provides a user interface with features like Real-time Analysis and Batch Processing Mode (using file uploads) for analyzing feedback.

The final trained model is saved in the directory code/customer-feedback-analyzer/models/feedback_classifier.
